{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "API_KEY = \"AIzaSyB3Ft4l3D1qyQDXpcLjEE5QdKHNXF4o3Zc\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "file_path = [\n",
    "    \"C:/Users/HP/Downloads/student_scores.xlsx\",\n",
    "\n",
    "    \"C:/Users/HP/OneDrive/Documents/DANNY DATA/Quiksight/quiksight/media/Melbourne_housing_FULL.csv\",\n",
    "\n",
    "    \"C:/Users/HP/OneDrive/Desktop/Datasets/road_accident_dataset.csv\",\n",
    "    \n",
    "    \"C:/Users/HP/OneDrive/Documents/MACHINE _LEARNING/data_sets/Electric_Vehicle_Charging_Stations.csv\",\n",
    "\n",
    "    \"C:/Users/HP/Downloads/car_price_dataset_v51ysjG.csv\"\n",
    "\n",
    "]\n",
    "# df = pd.read_excel(file_path[3])\n",
    "df = pd.read_csv(file_path[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <span style=\"color: yellow\">=========================================================================================================</span>\n",
    "#  Second version of issue identification test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gemini from openrouter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b style=\"color:lightblue\">Gemini API call function</b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "import google.generativeai as genai\n",
    "import pandas as pd\n",
    "\n",
    "def call_gemini_api(prompt, api_key, model_name=\"gemini-2.5-pro-exp-03-25\"):\n",
    "    \"\"\"\n",
    "    Calls the Gemini API using the Google Generative AI Python SDK.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The prompt or instruction to send.\n",
    "        api_key (str): Your Gemini API key.\n",
    "        model_name (str): The model to use (default is gemini-2.5-pro-exp-03-25).\n",
    "\n",
    "    Returns:\n",
    "        str: The generated response text.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        genai.configure(api_key=api_key)\n",
    "        model = genai.GenerativeModel(model_name)\n",
    "        response = model.generate_content(prompt)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        print(\"Error calling Gemini API:\", e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b style=\"color:lightblue\">Data description function</b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n    \"dataset_size\": {\\n        \"rows\": 132000,\\n        \"columns\": 30\\n    },\\n    \"column_details\": {\\n        \"Country\": {\\n            \"dtype\": \"object\",\\n            \"unique_values\": 10,\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Year\": {\\n            \"dtype\": \"int64\",\\n            \"unique_values\": 25,\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Month\": {\\n            \"dtype\": \"object\",\\n            \"unique_values\": 12,\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Day of Week\": {\\n            \"dtype\": \"object\",\\n            \"unique_values\": 7,\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Time of Day\": {\\n            \"dtype\": \"object\",\\n            \"unique_values\": 4,\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Urban/Rural\": {\\n            \"dtype\": \"object\",\\n            \"unique_values\": 2,\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Road Type\": {\\n            \"dtype\": \"object\",\\n            \"unique_values\": 3,\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Weather Conditions\": {\\n            \"dtype\": \"object\",\\n            \"unique_values\": 5,\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Visibility Level\": {\\n            \"dtype\": \"float64\",\\n            \"unique_values\": 132000,\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Number of Vehicles Involved\": {\\n            \"dtype\": \"int64\",\\n            \"unique_values\": 4,\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Speed Limit\": {\\n            \"dtype\": \"int64\",\\n            \"unique_values\": 90,\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Driver Age Group\": {\\n            \"dtype\": \"object\",\\n            \"unique_values\": 5,\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Driver Gender\": {\\n            \"dtype\": \"object\",\\n            \"unique_values\": 2,\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Driver Alcohol Level\": {\\n            \"dtype\": \"float64\",\\n            \"unique_values\": 132000,\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Driver Fatigue\": {\\n            \"dtype\": \"int64\",\\n            \"unique_values\": 2,\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Vehicle Condition\": {\\n            \"dtype\": \"object\",\\n            \"unique_values\": 3,\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Pedestrians Involved\": {\\n            \"dtype\": \"int64\",\\n            \"unique_values\": 3,\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Cyclists Involved\": {\\n            \"dtype\": \"int64\",\\n            \"unique_values\": 3,\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Accident Severity\": {\\n            \"dtype\": \"object\",\\n            \"unique_values\": 3,\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Number of Injuries\": {\\n            \"dtype\": \"int64\",\\n            \"unique_values\": 20,\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Number of Fatalities\": {\\n            \"dtype\": \"int64\",\\n            \"unique_values\": 5,\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Emergency Response Time\": {\\n            \"dtype\": \"float64\",\\n            \"unique_values\": 132000,\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Traffic Volume\": {\\n            \"dtype\": \"float64\",\\n            \"unique_values\": 132000,\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Road Condition\": {\\n            \"dtype\": \"object\",\\n            \"unique_values\": 4,\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Accident Cause\": {\\n            \"dtype\": \"object\",\\n            \"unique_values\": 5,\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Insurance Claims\": {\\n            \"dtype\": \"int64\",\\n            \"unique_values\": 10,\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Medical Cost\": {\\n            \"dtype\": \"float64\",\\n            \"unique_values\": 132000,\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Economic Loss\": {\\n            \"dtype\": \"float64\",\\n            \"unique_values\": 132000,\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Region\": {\\n            \"dtype\": \"object\",\\n            \"unique_values\": 5,\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Population Density\": {\\n            \"dtype\": \"float64\",\\n            \"unique_values\": 132000,\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        }\\n    },\\n    \"duplicate_rows\": [],\\n    \"missing_values_summary\": {\\n        \"Country\": {\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Year\": {\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Month\": {\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Day of Week\": {\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Time of Day\": {\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Urban/Rural\": {\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Road Type\": {\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Weather Conditions\": {\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Visibility Level\": {\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Number of Vehicles Involved\": {\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Speed Limit\": {\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Driver Age Group\": {\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Driver Gender\": {\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Driver Alcohol Level\": {\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Driver Fatigue\": {\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Vehicle Condition\": {\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Pedestrians Involved\": {\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Cyclists Involved\": {\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Accident Severity\": {\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Number of Injuries\": {\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Number of Fatalities\": {\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Emergency Response Time\": {\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Traffic Volume\": {\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Road Condition\": {\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Accident Cause\": {\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Insurance Claims\": {\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Medical Cost\": {\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Economic Loss\": {\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Region\": {\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        },\\n        \"Population Density\": {\\n            \"missing_count\": 0,\\n            \"missing_percentage\": 0.0\\n        }\\n    },\\n    \"numerical_summary\": {\\n        \"Year\": {\\n            \"count\": 132000.0,\\n            \"mean\": 2011.9733484848484,\\n            \"std\": 7.198623637459722,\\n            \"min\": 2000.0,\\n            \"25%\": 2006.0,\\n            \"50%\": 2012.0,\\n            \"75%\": 2018.0,\\n            \"max\": 2024.0\\n        },\\n        \"Visibility Level\": {\\n            \"count\": 132000.0,\\n            \"mean\": 275.03877575822486,\\n            \"std\": 129.92362456089026,\\n            \"min\": 50.001928084225526,\\n            \"25%\": 162.3388597158604,\\n            \"50%\": 274.6729904221862,\\n            \"75%\": 388.0141108270788,\\n            \"max\": 499.99964642424015\\n        },\\n        \"Number of Vehicles Involved\": {\\n            \"count\": 132000.0,\\n            \"mean\": 2.501227272727273,\\n            \"std\": 1.117271600541397,\\n            \"min\": 1.0,\\n            \"25%\": 2.0,\\n            \"50%\": 3.0,\\n            \"75%\": 3.0,\\n            \"max\": 4.0\\n        },\\n        \"Speed Limit\": {\\n            \"count\": 132000.0,\\n            \"mean\": 74.54406818181818,\\n            \"std\": 26.001447764276985,\\n            \"min\": 30.0,\\n            \"25%\": 52.0,\\n            \"50%\": 74.0,\\n            \"75%\": 97.0,\\n            \"max\": 119.0\\n        },\\n        \"Driver Alcohol Level\": {\\n            \"count\": 132000.0,\\n            \"mean\": 0.12523188046021863,\\n            \"std\": 0.07222478983921508,\\n            \"min\": 1.8257616145878064e-06,\\n            \"25%\": 0.06262978837222283,\\n            \"50%\": 0.12546764884764694,\\n            \"75%\": 0.1878763462768296,\\n            \"max\": 0.2499994577722172\\n        },\\n        \"Driver Fatigue\": {\\n            \"count\": 132000.0,\\n            \"mean\": 0.5005757575757576,\\n            \"std\": 0.5000015624518248,\\n            \"min\": 0.0,\\n            \"25%\": 0.0,\\n            \"50%\": 1.0,\\n            \"75%\": 1.0,\\n            \"max\": 1.0\\n        },\\n        \"Pedestrians Involved\": {\\n            \"count\": 132000.0,\\n            \"mean\": 1.0007727272727274,\\n            \"std\": 0.8163044382271137,\\n            \"min\": 0.0,\\n            \"25%\": 0.0,\\n            \"50%\": 1.0,\\n            \"75%\": 2.0,\\n            \"max\": 2.0\\n        },\\n        \"Cyclists Involved\": {\\n            \"count\": 132000.0,\\n            \"mean\": 0.9983560606060606,\\n            \"std\": 0.8177635429266399,\\n            \"min\": 0.0,\\n            \"25%\": 0.0,\\n            \"50%\": 1.0,\\n            \"75%\": 2.0,\\n            \"max\": 2.0\\n        },\\n        \"Number of Injuries\": {\\n            \"count\": 132000.0,\\n            \"mean\": 9.508204545454545,\\n            \"std\": 5.774366328729591,\\n            \"min\": 0.0,\\n            \"25%\": 5.0,\\n            \"50%\": 9.0,\\n            \"75%\": 15.0,\\n            \"max\": 19.0\\n        },\\n        \"Number of Fatalities\": {\\n            \"count\": 132000.0,\\n            \"mean\": 1.995439393939394,\\n            \"std\": 1.412973575772936,\\n            \"min\": 0.0,\\n            \"25%\": 1.0,\\n            \"50%\": 2.0,\\n            \"75%\": 3.0,\\n            \"max\": 4.0\\n        },\\n        \"Emergency Response Time\": {\\n            \"count\": 132000.0,\\n            \"mean\": 32.49174590946877,\\n            \"std\": 15.889537090575828,\\n            \"min\": 5.00017717585775,\\n            \"25%\": 18.73287884010681,\\n            \"50%\": 32.534944092932584,\\n            \"75%\": 46.28952675212035,\\n            \"max\": 59.99958829573898\\n        },\\n        \"Traffic Volume\": {\\n            \"count\": 132000.0,\\n            \"mean\": 5041.929097553868,\\n            \"std\": 2860.671611495392,\\n            \"min\": 100.06262622744752,\\n            \"25%\": 2560.601299225987,\\n            \"50%\": 5037.909854997923,\\n            \"75%\": 7524.638161828263,\\n            \"max\": 9999.997467512789\\n        },\\n        \"Insurance Claims\": {\\n            \"count\": 132000.0,\\n            \"mean\": 4.495621212121212,\\n            \"std\": 2.8673471145471168,\\n            \"min\": 0.0,\\n            \"25%\": 2.0,\\n            \"50%\": 4.0,\\n            \"75%\": 7.0,\\n            \"max\": 9.0\\n        },\\n        \"Medical Cost\": {\\n            \"count\": 132000.0,\\n            \"mean\": 25198.454900771532,\\n            \"std\": 14274.771691342105,\\n            \"min\": 500.1100904837902,\\n            \"25%\": 12836.93359603349,\\n            \"50%\": 25188.20266892139,\\n            \"75%\": 37529.024898534815,\\n            \"max\": 49999.93013044369\\n        },\\n        \"Economic Loss\": {\\n            \"count\": 132000.0,\\n            \"mean\": 50437.50561498467,\\n            \"std\": 28584.290821742743,\\n            \"min\": 1000.3350852608436,\\n            \"25%\": 25692.81734277761,\\n            \"50%\": 50395.499874027315,\\n            \"75%\": 75186.62609294702,\\n            \"max\": 99999.62296808336\\n        },\\n        \"Population Density\": {\\n            \"count\": 132000.0,\\n            \"mean\": 2506.4762225681893,\\n            \"std\": 1440.6463518432424,\\n            \"min\": 10.002669482920254,\\n            \"25%\": 1258.1582991679616,\\n            \"50%\": 2506.2033327127465,\\n            \"75%\": 3756.65295008532,\\n            \"max\": 4999.9917445094015\\n        }\\n    },\\n    \"outlier_summary\": {\\n        \"Year\": {\\n            \"iqr_outliers\": [],\\n            \"modified_z_outliers\": [],\\n            \"total_outlier_percentage\": 0.0\\n        },\\n        \"Visibility Level\": {\\n            \"iqr_outliers\": [],\\n            \"modified_z_outliers\": [],\\n            \"total_outlier_percentage\": 0.0\\n        },\\n        \"Number of Vehicles Involved\": {\\n            \"iqr_outliers\": [],\\n            \"modified_z_outliers\": [],\\n            \"total_outlier_percentage\": 0.0\\n        },\\n        \"Speed Limit\": {\\n            \"iqr_outliers\": [],\\n            \"modified_z_outliers\": [],\\n            \"total_outlier_percentage\": 0.0\\n        },\\n        \"Driver Alcohol Level\": {\\n            \"iqr_outliers\": [],\\n            \"modified_z_outliers\": [],\\n            \"total_outlier_percentage\": 0.0\\n        },\\n        \"Driver Fatigue\": {\\n            \"iqr_outliers\": [],\\n            \"modified_z_outliers\": [],\\n            \"total_outlier_percentage\": 0.0\\n        },\\n        \"Pedestrians Involved\": {\\n            \"iqr_outliers\": [],\\n            \"modified_z_outliers\": [],\\n            \"total_outlier_percentage\": 0.0\\n        },\\n        \"Cyclists Involved\": {\\n            \"iqr_outliers\": [],\\n            \"modified_z_outliers\": [],\\n            \"total_outlier_percentage\": 0.0\\n        },\\n        \"Number of Injuries\": {\\n            \"iqr_outliers\": [],\\n            \"modified_z_outliers\": [],\\n            \"total_outlier_percentage\": 0.0\\n        },\\n        \"Number of Fatalities\": {\\n            \"iqr_outliers\": [],\\n            \"modified_z_outliers\": [],\\n            \"total_outlier_percentage\": 0.0\\n        },\\n        \"Emergency Response Time\": {\\n            \"iqr_outliers\": [],\\n            \"modified_z_outliers\": [],\\n            \"total_outlier_percentage\": 0.0\\n        },\\n        \"Traffic Volume\": {\\n            \"iqr_outliers\": [],\\n            \"modified_z_outliers\": [],\\n            \"total_outlier_percentage\": 0.0\\n        },\\n        \"Insurance Claims\": {\\n            \"iqr_outliers\": [],\\n            \"modified_z_outliers\": [],\\n            \"total_outlier_percentage\": 0.0\\n        },\\n        \"Medical Cost\": {\\n            \"iqr_outliers\": [],\\n            \"modified_z_outliers\": [],\\n            \"total_outlier_percentage\": 0.0\\n        },\\n        \"Economic Loss\": {\\n            \"iqr_outliers\": [],\\n            \"modified_z_outliers\": [],\\n            \"total_outlier_percentage\": 0.0\\n        },\\n        \"Population Density\": {\\n            \"iqr_outliers\": [],\\n            \"modified_z_outliers\": [],\\n            \"total_outlier_percentage\": 0.0\\n        }\\n    }\\n}'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def detect_outliers(df):\n",
    "    \"\"\"Detects outliers using IQR and Modified Z-score methods and returns outlier values.\"\"\"\n",
    "    outlier_summary = {}\n",
    "\n",
    "    for col in df.select_dtypes(include=[\"number\"]).columns:\n",
    "        data = df[col].dropna()\n",
    "\n",
    "        # IQR Method\n",
    "        Q1 = data.quantile(0.25)\n",
    "        Q3 = data.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        iqr_lower = Q1 - 1.5 * IQR\n",
    "        iqr_upper = Q3 + 1.5 * IQR\n",
    "        iqr_outliers = data[(data < iqr_lower) | (data > iqr_upper)]\n",
    "\n",
    "        # Modified Z-score Method\n",
    "        median = np.median(data)\n",
    "        mad = np.median(np.abs(data - median))\n",
    "        if mad == 0:\n",
    "            z_outliers = pd.Series()  # Empty Series if no variability\n",
    "        else:\n",
    "            modified_z_scores = 0.6745 * (data - median) / mad\n",
    "            z_outliers = data[np.abs(modified_z_scores) > 3.5]\n",
    "\n",
    "        # Total Outlier Percentage\n",
    "        total_outlier_percentage = round(((len(iqr_outliers) + len(z_outliers)) / len(data)) * 100, 2)\n",
    "\n",
    "        outlier_summary[col] = {\n",
    "            \"iqr_outliers\": iqr_outliers.tolist(),\n",
    "            \"modified_z_outliers\": z_outliers.tolist(),\n",
    "            \"total_outlier_percentage\": total_outlier_percentage,\n",
    "        }\n",
    "\n",
    "    return outlier_summary\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def data_information(df):\n",
    "    \"\"\"Generates a structured dataset summary for AI processing.\"\"\"\n",
    "\n",
    "    num_rows, num_columns = df.shape\n",
    "    outlier_summary = detect_outliers(df)\n",
    "\n",
    "    # Duplicate rows\n",
    "    duplicate_rows = df[df.duplicated(keep=False)].sort_values(by=list(df.columns))\n",
    "\n",
    "    # Missing values\n",
    "    missing_values = df.isnull().sum()\n",
    "    missing_percentage = (missing_values / num_rows * 100).round(3)\n",
    "\n",
    "    column_details = {\n",
    "        col: {\n",
    "            \"dtype\": str(df[col].dtype),\n",
    "            \"unique_values\": int(df[col].nunique()),\n",
    "            \"missing_count\": int(missing_values[col]),\n",
    "            \"missing_percentage\": float(missing_percentage[col]),\n",
    "        }\n",
    "        for col in df.columns\n",
    "    }\n",
    "\n",
    "    numerical_summary = df.describe().to_dict()\n",
    "\n",
    "    context = {\n",
    "        \"dataset_size\": {\"rows\": num_rows, \"columns\": num_columns},\n",
    "        \"column_details\": column_details,\n",
    "        \"duplicate_rows\": duplicate_rows.to_dict(orient='records'), #send the actual rows.\n",
    "        \"missing_values_summary\": {col: {\"missing_count\": int(missing_values[col]), \"missing_percentage\": float(missing_percentage[col])} for col in df.columns},\n",
    "        \"numerical_summary\": numerical_summary,\n",
    "        \"outlier_summary\": outlier_summary,\n",
    "    }\n",
    "\n",
    "    return context\n",
    "\n",
    "\n",
    "\n",
    "# Convert to JSON string for API request\n",
    "json_dataset_context = json.dumps(data_information(df), indent=4)\n",
    "json_dataset_context\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b style=\"color:lightblue\">Analyze smaller datasets function</b> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Large Datasets (10000+)\n",
    "### This will probably be the same one to handle smaller ones too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def analyze_dataframe(df, api_key, chunk_size=10000):\n",
    "    \"\"\"Analyzes a large DataFrame using an LLM through chunking and summarization with proper chunk tracking.\"\"\"\n",
    "    \n",
    "    rows = len(df)\n",
    "\n",
    "    # 1. Summary Statistics and Metadata First\n",
    "    prompt_metadata = f\"\"\"\n",
    "    You are a data analyst specializing in exploratory data analysis (EDA). \n",
    "    Analyze the following dataset structure and provide a concise, structured summary:\n",
    "\n",
    "    ### Dataset Overview:\n",
    "    - **Column Names and Descriptions:** {json_dataset_context}\n",
    "    - **Primary Data Characteristics:** Identify categorical vs. numerical columns.\n",
    "    - **Common Patterns:** Highlight notable distributions, frequent values, or standard formats.\n",
    "\n",
    "    ### Your Analysis Should Include:\n",
    "    1. **General Dataset Summary**: Provide a 3-5 sentence summary of the dataset's overall structure.  \n",
    "    2. **Potential Data Quality Issues**: Mention any inconsistencies, missing values, or formatting concerns.  \n",
    "    3. **Insights on Data Readiness**: Would this dataset be ready for analysis? If not, what steps should be taken?\n",
    "\n",
    "    Keep your response **concise and structured**.\n",
    "    \"\"\"\n",
    "    metadata_summary = call_gemini_api(prompt_metadata, api_key)\n",
    "    if metadata_summary:\n",
    "        print(\"Metadata Summary:\", metadata_summary)\n",
    "    else:\n",
    "        print(\"Failed to retrieve metadata summary.\")\n",
    "        return\n",
    "\n",
    "    # 2. Chunking and Summarization with Chunk Tracking\n",
    "    chunk_summaries = []\n",
    "    processed_chunks = 0\n",
    "    total_chunks = (rows + chunk_size - 1) // chunk_size\n",
    "\n",
    "    for i in range(0, rows, chunk_size):\n",
    "        chunk = df[i:i + chunk_size]\n",
    "        csv_chunk = chunk.to_csv(index=False)\n",
    "\n",
    "        prompt_chunk = f\"\"\"\n",
    "        You are an expert data quality analyst. Analyze the following chunk of a dataset: {csv_chunk}\n",
    "        \n",
    "        ### Analysis Scope:\n",
    "        Provide insights in the following structured format:\n",
    "\n",
    "        1. **Missing Data**:\n",
    "        - List columns with missing values.\n",
    "        - Provide the percentage of missing data per column.\n",
    "        - Recommend imputation strategies if applicable.\n",
    "\n",
    "        2. **Data Type Issues**:\n",
    "        - Identify columns with inconsistent data types.\n",
    "        - Detect numbers stored as text, incorrect date formats, or category mismatches.\n",
    "\n",
    "        3. **Uniqueness & Duplicates**:\n",
    "        - Report the count of unique values per column.\n",
    "        - Identify duplicate rows and provide their percentage.\n",
    "\n",
    "        4. **Outliers & Anomalies**:\n",
    "        - Detect statistical outliers using IQR or Z-score.\n",
    "        - Highlight extreme or unexpected values.\n",
    "\n",
    "        5. **Formatting & Consistency Issues**:\n",
    "        - Detect inconsistencies in capitalization, date formats, and numerical precision.\n",
    "        - Identify the presence of special characters, typos, or inconsistent naming conventions.\n",
    "\n",
    "        ### Additional Guidelines:\n",
    "        - **Do Not Make Assumptions**: Base responses strictly on the provided chunk.\n",
    "        - **Be Concise and Structured**: Use bullet points or numbered lists.\n",
    "        - **Keep it Relevant**: Avoid unnecessary explanations.\n",
    "        \"\"\"\n",
    "        chunk_summary = call_gemini_api(prompt_chunk, api_key)\n",
    "        if chunk_summary:\n",
    "            print(f\"Chunk {i} LOADED SUCCESSFULLY\")\n",
    "            chunk_summaries.append(chunk_summary)\n",
    "            processed_chunks += 1\n",
    "        else:\n",
    "            print(f\"Chunk Request failed for chunk {i}\")\n",
    "\n",
    "    # 3. Conditional Synthesis of Summaries\n",
    "    if processed_chunks == total_chunks:\n",
    "        print(\"PROMPT SYNTHESIS SECTION\")\n",
    "        print(f\"Processed {processed_chunks} of {total_chunks} chunks.\")\n",
    "\n",
    "        prompt_synthesis = f\"\"\"\n",
    "        You are a senior data quality expert. Synthesize the following chunk analyses into a final report: {json.dumps(chunk_summaries, indent=2)}\n",
    "\n",
    "        ### Deliverables:\n",
    "        1. **Overall Data Quality Summary** (3-5 sentences):\n",
    "        - What are the most common issues found?\n",
    "        - Are there major concerns affecting usability?\n",
    "\n",
    "        2. **Data Clean Score (0-100%)**:\n",
    "        - Assign a **data quality score** based on missing data, inconsistencies, and outliers.\n",
    "        - Justify the assigned score with specific reasoning.\n",
    "\n",
    "        3. **Key Areas for Improvement**:\n",
    "        - Highlight **top 3** most critical data issues.\n",
    "        - Provide **specific, actionable recommendations** to fix them.\n",
    "\n",
    "        ### Additional Guidelines:\n",
    "        - Keep the response structured.\n",
    "        - Avoid repeating individual chunk resultsâ€”focus on overall trends.\n",
    "        - Provide insights that are **useful for a data engineer preparing this dataset**.\n",
    "        \"\"\"\n",
    "        final_summary = call_gemini_api(prompt_synthesis, api_key)\n",
    "        if final_summary:\n",
    "            print(\"Final Summary:\", final_summary)\n",
    "        else:\n",
    "            print(\"Failed to generate final summary.\")\n",
    "    else:\n",
    "        print(\"Synthesis skipped. Processed\", processed_chunks, \"of\", total_chunks, \"chunks.\")\n",
    "\n",
    "analyze_dataframe(df, API_KEY) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "\n",
    "def generate_data_dictionary(df, api_key, num_samples=3, delay=3):  # Added delay parameter\n",
    "\n",
    "    sample_data = df.sample(min(num_samples, len(df)), random_state=42).to_dict(orient=\"records\")\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are analyzing a dataset. Below is a small sample:\n",
    "\n",
    "    **Sample Data:**\n",
    "    {json.dumps(sample_data, indent=4)}\n",
    "\n",
    "    **Task:**\n",
    "    - Identify what each column represents.\n",
    "    - Provide a short, clear description of each column.\n",
    "    - Identify if the column is **categorical, numerical, date, or identifier**.\n",
    "    - Specify the data type (text, numeric, date, boolean).\n",
    "    - Mention how the column may relate to others (if applicable). Make this a bit more detailed. Don't be rigid with description language here.\n",
    "    - Return **only valid JSON output**, without extra text.\n",
    "\n",
    "    **Expected JSON Output Format:**\n",
    "    {{\n",
    "        \"column_name\": {{\n",
    "            \"description\": \"Short explanation of what this column represents.\",\n",
    "            \"type\": \"categorical/numerical/date/identifier\",\n",
    "            \"data_type\": \"text/numeric/date/boolean\",\n",
    "            \"format\": \"e.g., YYYY-MM-DD for dates, 2 decimal places for floats\",\n",
    "            \"relationships\": \"Optional: Mention related columns if obvious\"\n",
    "        }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Introduce a delay to avoid hitting the rate limit\n",
    "        time.sleep(delay)  # Adjust delay if needed\n",
    "\n",
    "        response = call_gemini_api(prompt, api_key=api_key)\n",
    "\n",
    "        # Clean potential markdown formatting\n",
    "        cleaned_response = response.strip().replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "\n",
    "        # Validate and parse JSON\n",
    "        response_dict = json.loads(cleaned_response)\n",
    "        return response_dict\n",
    "\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Invalid JSON received:\", response)\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(\"API Request Failed:\", str(e))\n",
    "        return None\n",
    "\n",
    "\n",
    "# Usage with delay\n",
    "data_dictionary = generate_data_dictionary(df, API_KEY, delay=2)\n",
    "Json_data_dictionary = json.dumps(data_dictionary, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"summary\": \"This dataset provides comprehensive records of traffic accidents, detailing temporal, geographical, environmental, vehicular, and human factors, alongside accident outcomes like severity, injuries, fatalities, and associated costs. It appears suitable for business intelligence analysis related to accident patterns, causes, and impacts.\",\n",
      "    \"issues\": {\n",
      "        \"critical\": [\n",
      "            {\n",
      "                \"column\": \"Country / Region\",\n",
      "                \"issue\": \"Inconsistent mapping between 'Country' and 'Region'. Sample data shows instances like 'Canada' mapped to 'Australia', 'Asia', or 'South America', and 'Germany' mapped to 'North America'.\",\n",
      "                \"impact\": \"Critically undermines the reliability of any geographical analysis, regional comparisons, or location-based reporting. Prevents accurate aggregation by region and raises governance concerns about data lineage and accuracy.\"\n",
      "            }\n",
      "        ],\n",
      "        \"moderate\": [\n",
      "            {\n",
      "                \"column\": \"Weather Conditions / Road Condition\",\n",
      "                \"issue\": \"Logical inconsistencies observed between 'Weather Conditions' and 'Road Condition'. Examples include 'Snowy' weather with 'Dry' road conditions, or 'Rainy' weather with 'Snow-covered' roads.\",\n",
      "                \"impact\": \"Reduces confidence in environmental factor analysis. Could lead to incorrect conclusions about the impact of weather vs. road maintenance on accidents. Affects reliability for modeling or root cause analysis.\"\n",
      "            },\n",
      "            {\n",
      "                \"column\": \"Accident Severity / Number of Injuries / Number of Fatalities\",\n",
      "                \"issue\": \"Potential logical inconsistencies. Sample data shows 'Minor' severity accidents with fatalities, or 'Severe' accidents with 0 injuries/fatalities. While possible in specific scenarios, requires validation.\",\n",
      "                \"impact\": \"May lead to misinterpretation of accident severity definitions or inaccuracies in reporting impact. Could skew analysis linking severity to outcomes if data points are incorrect.\"\n",
      "            },\n",
      "            {\n",
      "                \"column\": \"Visibility Level / Driver Alcohol Level / Emergency Response Time / Traffic Volume / Medical Cost / Economic Loss / Population Density\",\n",
      "                \"issue\": \"Numerical columns have an extremely high number of unique values (equal to row count), suggesting high precision (many decimal places) or potentially noisy data.\",\n",
      "                \"impact\": \"While high granularity can be useful, excessive precision might imply noise or be unnecessary for most BI reporting, potentially complicating aggregations or visualizations without adding significant insight. Requires verification if the precision is meaningful.\"\n",
      "            }\n",
      "        ],\n",
      "        \"minor\": [\n",
      "            {\n",
      "                \"column\": \"Numerical Precision (Multiple Columns)\",\n",
      "                \"issue\": \"Float columns (e.g., Costs, Visibility, Response Time) display excessive decimal places.\",\n",
      "                \"impact\": \"Primarily a formatting/presentation issue. Can make reports look cluttered and may imply a level of precision that doesn't exist or isn't required for business decisions. Low impact on core analysis but affects usability.\"\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    \"recommendations\": [\n",
      "        \"Investigate and correct the 'Country' to 'Region' mapping immediately. Establish a validated master list or rule for this relationship.\",\n",
      "        \"Implement data validation rules to ensure logical consistency between 'Weather Conditions' and 'Road Condition'. Flag or correct inconsistencies.\",\n",
      "        \"Review the definitions and recording process for 'Accident Severity', 'Number of Injuries', and 'Number of Fatalities' to confirm logic or identify data entry errors. Validate unusual combinations.\",\n",
      "        \"Standardize the precision (number of decimal places) for numerical fields like costs, visibility, traffic volume, etc., based on business requirements and meaningful accuracy.\",\n",
      "        \"Consult data source owners or subject matter experts to understand the meaning and required precision of high-granularity numerical fields (e.g., 'Visibility Level').\"\n",
      "    ],\n",
      "    \"data_quality_score\": 70,\n",
      "    \"justification\": \"The dataset scores moderately due to being complete (no missing values) and structurally sound (no duplicates, correct data types). However, critical inconsistencies in geographical mapping ('Country'/'Region') and moderate logical contradictions ('Weather'/'Road Condition', 'Severity'/Outcomes) significantly impact its reliability for key analyses and raise governance concerns. While fixable, these issues require immediate attention before the data can be fully trusted for strategic decision-making.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "\n",
    "def analyze_larger_dataframe(df, API_KEY, delay=2):\n",
    "    \"\"\"\n",
    "    Analyzes the dataset for potential issues, assigns a data quality score, \n",
    "    and presents findings in a structured, business-friendly manner.\n",
    "    \n",
    "    Args:\n",
    "    - df (pd.DataFrame): The dataset to analyze.\n",
    "    - API_KEY (str): The API key for the AI model.\n",
    "    \n",
    "    Returns:\n",
    "    - str: A structured report highlighting data issues and quality insights.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert sample of dataset to JSON for context\n",
    "    sample_size = int(min(max(0.01 * len(df), 5), 500))  # 1% of data, min 5, max 500\n",
    "    dataset_sample = df.sample(sample_size, random_state=42).to_dict(orient=\"records\")\n",
    "\n",
    "    # Ensure Json_data_dictionary and json_dataset_context are valid\n",
    "    if not Json_data_dictionary or not isinstance(Json_data_dictionary, str):\n",
    "        print(\"Error: Json_data_dictionary is missing or invalid.\")\n",
    "        return None\n",
    "\n",
    "    if not json_dataset_context or not isinstance(json_dataset_context, str):\n",
    "        print(\"Error: json_dataset_context is missing or invalid.\")\n",
    "        return None\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a data quality analyst specializing in **business intelligence and data governance**. \n",
    "    Your task is to analyze a dataset and provide a **structured, business-friendly** summary \n",
    "    highlighting data issues, anomalies, and areas for improvement.\n",
    "\n",
    "    ---\n",
    "    ### **Dataset Overview**\n",
    "    - **Context**: This dataset is provided with a data dictionary and metadata.\n",
    "    - **Sample Data**: {json.dumps(dataset_sample, indent=4)}\n",
    "    - **Data Dictionary**: {Json_data_dictionary}\n",
    "    - **Metadata Summary**: {json_dataset_context}\n",
    "\n",
    "    ---\n",
    "    ### **Analysis Objectives**\n",
    "    1. **Provide a High-Level Summary**  \n",
    "       - What does this dataset seem to represent?\n",
    "       - What key columns stand out?\n",
    "       - Any **noteworthy observations** at first glance?\n",
    "\n",
    "    2. **Identify Data Issues** (Categorized by Severity)  \n",
    "       Group issues based on their potential impact:\n",
    "       - **Critical Issues (Must Fix Immediately)**:  \n",
    "         - Examples: Extremely high missing values, duplicate records, inconsistent formats, incorrect data types.\n",
    "       - **Moderate Issues (Affects Data Reliability)**:  \n",
    "         - Examples: Outliers that may skew analysis, inconsistent category values, mixed data types.\n",
    "       - **Minor Issues (Low Impact, But Worth Fixing)**:  \n",
    "         - Examples: Minor formatting inconsistencies, redundant columns, minor data drift.\n",
    "\n",
    "    3. **Business Impact & Recommendations**  \n",
    "       - Explain **how these issues might affect business insights**.\n",
    "       - Suggest practical steps to **resolve or mitigate** the issues.\n",
    "\n",
    "    4. **Data Quality Score (0-100)**  \n",
    "       - Provide an overall data quality score based on how clean and reliable the dataset is.\n",
    "       - Justify the score with clear reasoning.\n",
    "\n",
    "    ---\n",
    "    ### **Response Format**\n",
    "    Ensure a **structured and user-friendly response** in this format:\n",
    "\n",
    "    ```json\n",
    "    {{\n",
    "#         \"summary\": \"Short, high-level description of the dataset.\",\n",
    "#         \"issues\": {{\n",
    "#             \"critical\": [\n",
    "#                 {{\"column\": \"Column Name\", \"issue\": \"Description of the issue\", \"impact\": \"Business impact\"}}\n",
    "#             ],\n",
    "#             \"moderate\": [\n",
    "#                 {{\"column\": \"Column Name\", \"issue\": \"Description of the issue\", \"impact\": \"Business impact\"}}\n",
    "#             ],\n",
    "#             \"minor\": [\n",
    "#                 {{\"column\": \"Column Name\", \"issue\": \"Description of the issue\", \"impact\": \"Business impact\"}}\n",
    "#             ]\n",
    "#         }},\n",
    "#         \"recommendations\": [\n",
    "#             \"Practical, business-friendly steps to improve data quality.\"\n",
    "#         ],\n",
    "#         \"data_quality_score\": 85  // Justification for the score\n",
    "#     }}\n",
    "    ```\n",
    "\n",
    "    **DO NOT include extra explanations or unnecessary text. Only return structured insights.**  \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    " \n",
    "\n",
    "    try:\n",
    "        time.sleep(delay)\n",
    "        response = call_gemini_api(prompt, api_key=API_KEY)\n",
    "        \n",
    "        if not response:\n",
    "            print(\"Empty API response\")\n",
    "            return None\n",
    "\n",
    "        # Extract JSON from markdown response\n",
    "        response = response.strip().replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "\n",
    "        response_dict = json.loads(response)\n",
    "        return response_dict\n",
    "\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Failed to parse JSON from:\\n{response}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Analysis failed: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "    \n",
    "\n",
    "# Example Usage:\n",
    "data_analysis_result = analyze_larger_dataframe(df, API_KEY)\n",
    "if data_analysis_result:\n",
    "\n",
    "    print(json.dumps(data_analysis_result, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
